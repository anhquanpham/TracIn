{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A-Mazing Proponents and Opponents",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhquanpham/TracIn/blob/master/imagenet/resnet50_imagenet_proponents_opponents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHQE7FAAuYmz"
      },
      "source": [
        "# A-Mazing Proponents and Opponents [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/frederick0329/TrackIn/blob/master/imagenet/resnet50_imagenet_proponents_opponents.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "*   ![A-Maze of interest](https://user-images.githubusercontent.com/3983652/86517275-8892d380-bddc-11ea-83b0-eea69408a4cd.jpeg)\n",
        "*   This colab shows an application of [TrackIn](https://arxiv.org/abs/2002.08484) - Proponents and Opponents in the training data of an example given a function of interest. The function of interest in this colab is the loss function of the example.\n",
        "*   This colab allows you to find examples in training data which would decrease (proponents) or increase (opponents) the loss function of a given example.\n",
        "*   Imagenet subset (10%) is used due to colab default RAM size (12G). To run the full imagenet, around 40G of RAM is required.     \n",
        "\n",
        "To Run\n",
        "\n",
        "*   Runtime -> Change Runtime Type -> TPU\n",
        "\n",
        "\n",
        "To adapt to your own data/model\n",
        "  *   Load your own model and select checkpoints.\n",
        "  *   Pick weights.\n",
        "  *   Replace loss function.\n",
        "  *   Write your own dataset loader.\n",
        "  *   [FAQ](https://drive.google.com/file/d/1zL3hwW4wFru49_-zwpmliRDdCahjumXa/view)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX2qZqC6x8uR"
      },
      "source": [
        "# Define varaibles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69DvGGYqx9Ef"
      },
      "source": [
        "IMAGENET_TFDS_DIR = \"tensorflow_datasets\" #@param {type:\"string\"}\n",
        "IMAGENET_TRAIN = \"imagenet/train\" #@param {type:\"string\"}\n",
        "IMAGENET_VAL = \"imagenet/validation\" #@param {type:\"string\"}\n",
        "CHECKPOINTS_PATH_FORMAT = \"ckpt{}\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-EAFzsezFnC"
      },
      "source": [
        "## Auth if your data is stored on gcs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxBpcfPr8IUN"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8dkqILWVIf8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNwpBRbHVIk2"
      },
      "source": [
        "# Clone git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdLBqYOlVJh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ae3852-a60f-434f-8481-161bc1e36f7c"
      },
      "source": [
        "!git clone https://github.com/frederick0329/TrackIn"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrackIn'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (60/60), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 150 (delta 32), reused 9 (delta 5), pack-reused 90 (from 1)\u001b[K\n",
            "Receiving objects: 100% (150/150), 69.61 MiB | 21.10 MiB/s, done.\n",
            "Resolving deltas: 100% (72/72), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIJ7CgiVugfJ"
      },
      "source": [
        "# Import and Utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tbYa-I5g40za",
        "outputId": "20d5adf1-8c45-4a87-cd08-c2e00adf73bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.15.0\n",
            "  Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n",
            "  Downloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow==2.15.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m284.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.0)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.0)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.14.1)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.0)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.74.0)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.7.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.1)\n",
            "Downloading tensorflow-2.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.3/475.3 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorstore 0.1.74 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.15.0 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.5.2 requires ml_dtypes>=0.4.0, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 numpy-1.26.4 protobuf-4.25.8 tensorboard-2.15.2 tensorflow-2.15.0 tensorflow-estimator-2.15.0 wrapt-1.14.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "keras",
                  "ml_dtypes",
                  "numpy",
                  "tensorflow",
                  "wrapt"
                ]
              },
              "id": "a2d36e5b8be04db1b375f001cee2ae08"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qNVolQEubxp"
      },
      "source": [
        "# @title Imports\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.image as mpimg\n",
        "import io\n",
        "import json\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import functools\n",
        "import sys\n",
        "sys.path.insert(0, \"./TrackIn/imagenet/resnet50\")\n",
        "import resnet"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE5Z9aOD7-mI",
        "outputId": "5d357f0e-8819-4991-eb61-fd53e8f2c727"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Connect to GPU\n",
        "try:\n",
        "  # Try to connect to a GPU, if available\n",
        "  gpu = tf.config.list_physical_devices('GPU')\n",
        "  if gpu:\n",
        "    print('Running on GPU ', gpu[0])\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "  else:\n",
        "    raise ValueError('ERROR: Not connected to a GPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "except ValueError as e:\n",
        "  raise BaseException('ERROR: Not connected to a GPU runtime; please see the previous cell in this notebook for instructions!') from e\n",
        "\n",
        "# tf.config.experimental_connect_to_cluster(tpu) # This line is specific to TPU and should be removed\n",
        "# tf.tpu.experimental.initialize_tpu_system(tpu) # This line is specific to TPU and should be removed\n",
        "# strategy = tf.distribute.experimental.TPUStrategy(tpu) # This line is specific to TPU and should be removed"
      ],
      "metadata": {
        "id": "sCHq1NJo86vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kAkLEIGu6dA"
      },
      "source": [
        "#@title Dataset Utils\n",
        "\n",
        "def _train_filename2id(filename):\n",
        "  filename = tf.strings.regex_replace(filename, \"n\", \"\")\n",
        "  filename = tf.strings.regex_replace(filename, \".JPEG\", \"\")\n",
        "  filename_split = tf.strings.split(filename, \"_\")\n",
        "  fileid = tf.strings.to_number(filename_split, tf.int32)\n",
        "  return fileid\n",
        "\n",
        "def _val_filename2id(filename):\n",
        "  filename = tf.strings.regex_replace(filename, \"ILSVRC2012_val_\", \"\")\n",
        "  filename = tf.strings.regex_replace(filename, \".JPEG\", \"\")\n",
        "  fileid = tf.strings.to_number(filename, tf.int32)\n",
        "  return fileid\n",
        "\n",
        "def _resize_image(image_bytes: tf.Tensor,\n",
        "                 height: int = 224,\n",
        "                 width: int = 224) -> tf.Tensor:\n",
        "  \"\"\"Resizes an image to a given height and width.\"\"\"\n",
        "  return tf.compat.v1.image.resize(\n",
        "      image_bytes, [height, width], method=tf.image.ResizeMethod.BILINEAR,\n",
        "      align_corners=False)\n",
        "\n",
        "# Calculated from the ImageNet training set\n",
        "MEAN_RGB = (0.485 * 255, 0.456 * 255, 0.406 * 255)\n",
        "STDDEV_RGB = (0.229 * 255, 0.224 * 255, 0.225 * 255)\n",
        "\n",
        "def mean_image_subtraction(\n",
        "    image_bytes,\n",
        "    means,\n",
        "    num_channels = 3,\n",
        "    dtype = tf.float32,\n",
        "):\n",
        "  \"\"\"Subtracts the given means from each image channel.\n",
        "\n",
        "  For example:\n",
        "    means = [123.68, 116.779, 103.939]\n",
        "    image_bytes = mean_image_subtraction(image_bytes, means)\n",
        "\n",
        "  Note that the rank of `image` must be known.\n",
        "\n",
        "  Args:\n",
        "    image_bytes: a tensor of size [height, width, C].\n",
        "    means: a C-vector of values to subtract from each channel.\n",
        "    num_channels: number of color channels in the image that will be distorted.\n",
        "    dtype: the dtype to convert the images to. Set to `None` to skip conversion.\n",
        "\n",
        "  Returns:\n",
        "    the centered image.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n",
        "      than three or if the number of channels in `image` doesn't match the\n",
        "      number of values in `means`.\n",
        "  \"\"\"\n",
        "  if image_bytes.get_shape().ndims != 3:\n",
        "    raise ValueError('Input must be of size [height, width, C>0]')\n",
        "\n",
        "  if len(means) != num_channels:\n",
        "    raise ValueError('len(means) must match the number of channels')\n",
        "\n",
        "  # We have a 1-D tensor of means; convert to 3-D.\n",
        "  # Note(b/130245863): we explicitly call `broadcast` instead of simply\n",
        "  # expanding dimensions for better performance.\n",
        "  means = tf.broadcast_to(means, tf.shape(image_bytes))\n",
        "  if dtype is not None:\n",
        "    means = tf.cast(means, dtype=dtype)\n",
        "\n",
        "  return image_bytes - means\n",
        "\n",
        "\n",
        "def standardize_image(\n",
        "    image_bytes,\n",
        "    stddev,\n",
        "    num_channels = 3,\n",
        "    dtype = tf.float32,\n",
        "):\n",
        "  \"\"\"Divides the given stddev from each image channel.\n",
        "\n",
        "  For example:\n",
        "    stddev = [123.68, 116.779, 103.939]\n",
        "    image_bytes = standardize_image(image_bytes, stddev)\n",
        "\n",
        "  Note that the rank of `image` must be known.\n",
        "\n",
        "  Args:\n",
        "    image_bytes: a tensor of size [height, width, C].\n",
        "    stddev: a C-vector of values to divide from each channel.\n",
        "    num_channels: number of color channels in the image that will be distorted.\n",
        "    dtype: the dtype to convert the images to. Set to `None` to skip conversion.\n",
        "\n",
        "  Returns:\n",
        "    the centered image.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n",
        "      than three or if the number of channels in `image` doesn't match the\n",
        "      number of values in `stddev`.\n",
        "  \"\"\"\n",
        "  if image_bytes.get_shape().ndims != 3:\n",
        "    raise ValueError('Input must be of size [height, width, C>0]')\n",
        "\n",
        "  if len(stddev) != num_channels:\n",
        "    raise ValueError('len(stddev) must match the number of channels')\n",
        "\n",
        "  # We have a 1-D tensor of stddev; convert to 3-D.\n",
        "  # Note(b/130245863): we explicitly call `broadcast` instead of simply\n",
        "  # expanding dimensions for better performance.\n",
        "  stddev = tf.broadcast_to(stddev, tf.shape(image_bytes))\n",
        "  if dtype is not None:\n",
        "    stddev = tf.cast(stddev, dtype=dtype)\n",
        "\n",
        "  return image_bytes / stddev\n",
        "\n",
        "# TPU does not allow tf.string and images with various size. Therefore, decode\n",
        "# and cropping cannot happen in the model.\n",
        "def _preprocess(inputs, split='train', image_size=224, crop_padding=32):\n",
        "  \"\"\"Apply image preprocessing.\"\"\"\n",
        "  filename = inputs['file_name']\n",
        "  image = inputs['image']\n",
        "  label = inputs['label']\n",
        "  if split == 'train':\n",
        "    fileid = _train_filename2id(filename)\n",
        "  else:\n",
        "    fileid = _val_filename2id(filename)\n",
        "  shape = tf.shape(image)\n",
        "  image_height = shape[0]\n",
        "  image_width = shape[1]\n",
        "\n",
        "  padded_center_crop_size = tf.cast(\n",
        "      ((image_size / (image_size + crop_padding)) *\n",
        "       tf.cast(tf.minimum(image_height, image_width), tf.float32)),\n",
        "      tf.int32)\n",
        "\n",
        "  offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n",
        "  offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n",
        "  crop_window = tf.stack([offset_height, offset_width,\n",
        "                          padded_center_crop_size, padded_center_crop_size])\n",
        "\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "        image,\n",
        "        offset_height=offset_height,\n",
        "        offset_width=offset_width,\n",
        "        target_height=padded_center_crop_size,\n",
        "        target_width=padded_center_crop_size)\n",
        "  image = _resize_image(image_bytes=image,\n",
        "                        height=image_size,\n",
        "                        width=image_size)\n",
        "  image = mean_image_subtraction(\n",
        "        image, MEAN_RGB)\n",
        "  image = standardize_image(\n",
        "        image, STDDEV_RGB)\n",
        "\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  label = tf.cast(label, tf.int32)\n",
        "  return fileid, image, label\n",
        "\n",
        "\n",
        "def make_get_dataset(split, batch_size):\n",
        "  def get_dataset(\n",
        "      input_context: tf.distribute.InputContext = None) -> tf.data.Dataset:\n",
        "    builder = tfds.builder(name='imagenet2012_subset/10pct', data_dir=IMAGENET_TFDS_DIR)\n",
        "    builder.download_and_prepare()\n",
        "\n",
        "    read_config = tfds.ReadConfig(\n",
        "        interleave_block_length=1)\n",
        "\n",
        "    _preprocess_fn = functools.partial(_preprocess, split=split)\n",
        "\n",
        "    ds = builder.as_dataset(\n",
        "        split=split,\n",
        "        as_supervised=False,\n",
        "        shuffle_files=False,\n",
        "        read_config=read_config)\n",
        "    ds = ds.map(_preprocess_fn,\n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size)\n",
        "\n",
        "    ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return ds\n",
        "  return get_dataset"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PvdJxMzu8gL"
      },
      "source": [
        "#@title Search Utils\n",
        "\n",
        "def find(loss_grad=None, activation=None, topk=50):\n",
        "  if loss_grad is None and activation is None:\n",
        "    raise ValueError('loss grad and activation cannot both be None.')\n",
        "  scores = []\n",
        "  scores_lg = []\n",
        "  scores_a = []\n",
        "  for i in range(len(trackin_train['image_ids'])):\n",
        "    if loss_grad is not None and activation is not None:\n",
        "      lg_sim = np.sum(trackin_train['loss_grads'][i] * loss_grad, axis=0)\n",
        "      a_sim = np.sum(trackin_train['activations'][i] * activation, axis=0)\n",
        "      scores.append(np.sum(lg_sim * a_sim))\n",
        "      scores_lg.append(np.sum(lg_sim))\n",
        "      scores_a.append(np.sum(a_sim))\n",
        "    elif loss_grad is not None:\n",
        "      scores.append(np.sum(trackin_train['loss_grads'][i] * loss_grad))\n",
        "    elif activation is not None:\n",
        "      scores.append(np.sum(trackin_train['activations'][i] * activation))\n",
        "\n",
        "  opponents = []\n",
        "  proponents = []\n",
        "  indices = np.argsort(scores)\n",
        "  for i in range(topk):\n",
        "    index = indices[-i-1]\n",
        "    proponents.append((\n",
        "        trackin_train['image_ids'][index],\n",
        "        trackin_train['probs'][index][0],\n",
        "        index_to_classname[str(trackin_train['predicted_labels'][index][0])][1],\n",
        "        index_to_classname[str(trackin_train['labels'][index])][1],\n",
        "        scores[index],\n",
        "        scores_lg[index] if scores_lg else None,\n",
        "        scores_a[index] if scores_a else None))\n",
        "    index = indices[i]\n",
        "    opponents.append((\n",
        "        trackin_train['image_ids'][index],\n",
        "        trackin_train['probs'][index][0],\n",
        "        index_to_classname[str(trackin_train['predicted_labels'][index][0])][1],\n",
        "        index_to_classname[str(trackin_train['labels'][index])][1],\n",
        "        scores[index],\n",
        "        scores_lg[index] if scores_lg else None,\n",
        "        scores_a[index] if scores_a else None))\n",
        "  return opponents, proponents\n",
        "\n",
        "IMAGENET_LABEL_DICT = './TrackIn/imagenet/imagenet_class_index.json'\n",
        "def get_id_synset_mapping():\n",
        "  imagenet_class_idx_path = IMAGENET_LABEL_DICT\n",
        "  with tf.io.gfile.GFile(imagenet_class_idx_path, \"r\") as f:\n",
        "    json_str = f.read()\n",
        "    index_to_classname = json.loads(json_str)\n",
        "  return index_to_classname\n",
        "index_to_classname = get_id_synset_mapping()\n",
        "\n",
        "def get_image(split, id):\n",
        "  if split == 'validation':\n",
        "    filepath = '{}/ILSVRC2012_val_{fileid:08d}.JPEG'.format(IMAGENET_VAL, fileid=id)\n",
        "    print('ILSVRC2012_val_{fileid:08d}.JPEG'.format(fileid=id))\n",
        "  else:\n",
        "    filepath = '{}/n0{}/n0{}_{}.JPEG'.format(IMAGENET_TRAIN, id[0], id[0], id[1])\n",
        "    print('n0{}_{}.JPEG'.format(id[0], id[1]))\n",
        "  try:\n",
        "    with tf.io.gfile.GFile(filepath, \"rb\") as f:\n",
        "      jpg_data = f.read()\n",
        "      image = mpimg.imread(io.BytesIO(jpg_data), format='JPG')\n",
        "    return image\n",
        "  except:\n",
        "    print('Failed to read image {}'.format(filepath))\n",
        "\n",
        "def find_and_show(trackin_dict, idx, vector='influence', idx_filename_mapping=None):\n",
        "  if vector == 'influence':\n",
        "    op, pp = find(trackin_dict['loss_grads'][idx], trackin_dict['activations'][idx])\n",
        "  elif vector == 'encoding':\n",
        "    op, pp = find(None, trackin_dict['activations'][idx])\n",
        "  elif vector == 'error':\n",
        "    op, pp = find(trackin_dict['loss_grads'][idx], None)\n",
        "  else:\n",
        "    raise ValueError('Unsupported vector type.')\n",
        "  print('Query image from validation: ')\n",
        "  print('label: {}, prob: {}, predicted_label: {}'.format(\n",
        "      index_to_classname[str(trackin_dict['labels'][idx])][1],\n",
        "      trackin_dict['probs'][idx][0],\n",
        "      index_to_classname[str(trackin_dict['predicted_labels'][idx][0])][1]))\n",
        "  if idx_filename_mapping:\n",
        "    img = mpimg.imread(io.BytesIO(idx_filename_mapping[idx]), format='JPG')\n",
        "  else:\n",
        "    img = get_image('validation', trackin_dict['image_ids'][idx])\n",
        "  if img is not None:\n",
        "    plt.imshow(img, interpolation='nearest')\n",
        "    plt.show()\n",
        "  print(\"=\"*50)\n",
        "  print('Proponents: ')\n",
        "  for p in pp:\n",
        "    print('label: {}, prob: {}, predicted_label: {}, influence: {}'.format(p[3], p[1], p[2], p[4]))\n",
        "    if p[5] and p[6]:\n",
        "      print('error_similarity: {}, encoding_similarity: {}'.format(p[5], p[6]))\n",
        "    img = get_image('train', p[0])\n",
        "    if img is not None:\n",
        "      plt.imshow(img, interpolation='nearest')\n",
        "      plt.show()\n",
        "  print(\"=\"*50)\n",
        "  print('Opponents: ')\n",
        "  for o in op:\n",
        "    print('label: {}, prob: {}, predicted_label: {}, influence: {}'.format(o[3], o[1], o[2], o[4]))\n",
        "    if o[5] and o[6]:\n",
        "      print('error_similarity: {}, encoding_similarity: {}'.format(o[5], o[6]))\n",
        "    img = get_image('train', o[0])\n",
        "    if img is not None:\n",
        "      plt.imshow(img, interpolation='nearest')\n",
        "      plt.show()\n",
        "  print(\"=\"*50)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmCt7RGtvIca"
      },
      "source": [
        "# Init models/checkpoints\n",
        "\n",
        "\n",
        "\n",
        "* Resnet50 - 75.8% accuracy\n",
        "* Pick 30, 60, 90th checkpoint\n",
        "* Model checkpoint weights are converted to saved models so the colab does not depend on model code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6YoulOMvI6_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b4e2193-57b3-43a5-e9ba-97a747d401f4"
      },
      "source": [
        "with strategy.scope():\n",
        "  models_penultimate = []\n",
        "  models_last = []\n",
        "  for i in [30, 60, 90]:\n",
        "    model = resnet.resnet50(1000)\n",
        "    model.load_weights(CHECKPOINTS_PATH_FORMAT.format(i))\n",
        "    models_penultimate.append(tf.keras.Model(model.layers[0].input, model.layers[-3].output))\n",
        "    models_last.append(model.layers[-2])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras._tf_keras'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1867565341.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mmodels_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINTS_PATH_FORMAT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodels_penultimate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/./TrackIn/imagenet/resnet50/resnet.py\u001b[0m in \u001b[0;36mresnet50\u001b[0;34m(num_classes, batch_size, use_l2_regularizer, batch_norm_decay, batch_norm_epsilon)\u001b[0m\n\u001b[1;32m    238\u001b[0m   \"\"\"\n\u001b[1;32m    239\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m   \u001b[0mimg_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_module_globals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Emit a warning if one was specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras._tf_keras'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnEENz8avQQG"
      },
      "source": [
        "# Find Proponents and Opponents for a given test example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmdetwcKA8O8"
      },
      "source": [
        "@tf.function\n",
        "def run(inputs):\n",
        "  imageids, images, labels = inputs\n",
        "  # ignore bias for simplicity\n",
        "  loss_grads = []\n",
        "  activations = []\n",
        "  for mp, ml in zip(models_penultimate, models_last):\n",
        "    h = mp(images)\n",
        "    logits = ml(h)\n",
        "    probs = tf.nn.softmax(logits)\n",
        "    loss_grad = tf.one_hot(labels, 1000) - probs\n",
        "    activations.append(h)\n",
        "    loss_grads.append(loss_grad)\n",
        "\n",
        "  # Using probs from last checkpoint\n",
        "  probs, predicted_labels = tf.math.top_k(probs, k=1)\n",
        "\n",
        "  return imageids, tf.stack(loss_grads, axis=-1), tf.stack(activations, axis=-1), labels, probs, predicted_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2KWJbgovSiJ"
      },
      "source": [
        "def get_trackin_grad(ds):\n",
        "  image_ids_np = []\n",
        "  loss_grads_np = []\n",
        "  activations_np = []\n",
        "  labels_np = []\n",
        "  probs_np = []\n",
        "  predicted_labels_np = []\n",
        "  for d in ds:\n",
        "    imageids_replicas, loss_grads_replica, activations_replica, labels_replica, probs_replica, predictied_labels_replica = strategy.run(run, args=(d,))\n",
        "    for imageids, loss_grads, activations, labels, probs, predicted_labels in zip(\n",
        "        strategy.experimental_local_results(imageids_replicas),\n",
        "        strategy.experimental_local_results(loss_grads_replica),\n",
        "        strategy.experimental_local_results(activations_replica),\n",
        "        strategy.experimental_local_results(labels_replica),\n",
        "        strategy.experimental_local_results(probs_replica),\n",
        "        strategy.experimental_local_results(predictied_labels_replica)):\n",
        "      if imageids.shape[0] == 0:\n",
        "        continue\n",
        "      image_ids_np.append(imageids.numpy())\n",
        "      loss_grads_np.append(loss_grads.numpy())\n",
        "      activations_np.append(activations.numpy())\n",
        "      labels_np.append(labels.numpy())\n",
        "      probs_np.append(probs.numpy())\n",
        "      predicted_labels_np.append(predicted_labels.numpy())\n",
        "  return {'image_ids': np.concatenate(image_ids_np),\n",
        "          'loss_grads': np.concatenate(loss_grads_np),\n",
        "          'activations': np.concatenate(activations_np),\n",
        "          'labels': np.concatenate(labels_np),\n",
        "          'probs': np.concatenate(probs_np),\n",
        "          'predicted_labels': np.concatenate(predicted_labels_np)\n",
        "         }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtL7wlEyvWTj"
      },
      "source": [
        "## Build Imagenet Train Vectors\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu0rpCSKvUVo"
      },
      "source": [
        "ds_train = strategy.experimental_distribute_datasets_from_function(make_get_dataset('train', 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pY4FuvovZRZ"
      },
      "source": [
        "start = time.time()\n",
        "trackin_train = get_trackin_grad(ds_train)\n",
        "end = time.time()\n",
        "print(datetime.timedelta(seconds=end - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mICyWNRHAVe7"
      },
      "source": [
        "## Build Imagenet Val Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Dd5eTMAXDw"
      },
      "source": [
        "ds_val = strategy.experimental_distribute_datasets_from_function(make_get_dataset('validation', 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sUph5uVAYq2"
      },
      "source": [
        "start = time.time()\n",
        "trackin_val = get_trackin_grad(ds_val)\n",
        "end = time.time()\n",
        "print(datetime.timedelta(seconds=end - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "989fUR7uvkeC"
      },
      "source": [
        "## Pick an index from Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHiyF1JVvk8s"
      },
      "source": [
        "find_and_show(trackin_val, 83, 'influence')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}